# kafka配置
spring.kafka.bootstrap-servers=127.0.0.1:9092 
spring.kafka.consumer.group-id=0

#当Kafka中没有初始偏移量或者服务器上不再存在当前偏移量时该怎么办，默认值为latest，表示自动将偏移重置为最新的偏移量
#可选的值为latest, earliest, none
spring.kafka.consumer.auto-offset-reset=earliest

# 是否采用自动提交的机制， 默认n秒钟，一个 Consumer 将会提交它的 Offset 给 Kafka，或者每一次数据从指定的 Topic 取回时，将会提交最后一次的 Offset。
spring.kafka.consumer.enable-auto-commit=true
# 如果'enable.auto.commit'为true，消费者偏移自动提交给Kafka的频率（以毫秒为单位）
spring.kafka.consumer.auto-commit-interval=100
#=======set comsumer max fetch.byte 2*1024*1024=============

# # 一次fetch请求，从一个partition中取得的records最大大小。
# 如果在从topic中第一个非空的partition取消息时，如果取到的第一个record的大小就超过这个配置时，仍然会读取这个record，
# 也就是说在这片情况下，只会返回这一条record。broker、topic都会对producer发给它的message size做限制。
# 所以在配置这值时，可以参考broker的message.max.bytes 和 topic的max.message.bytes的配置。默认：1 * 1024 * 1024 = 1048576
spring.kafka.consumer.properties.max.partition.fetch.bytes=2097152
#spring.kafka.listener.ack-mode=manual
# max.poll.records条数据需要在session.timeout.ms这个时间内处理完，默认：500
#spring.kafka.consumer.max-poll-records=100
#每个listener拥有一个处理线程
#spring.kafka.listener.concurrency=1
# Key的反序列化器类，实现类实现了接口org.apache.kafka.common.serialization.Deserializer
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# 值的反序列化类。实现了org.apache.kafka.common.serialization.Deserializer接口
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer


